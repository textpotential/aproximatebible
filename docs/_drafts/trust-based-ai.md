Why bother with trust? Is it even a force worth considering or is it simply a story we tell ourselves and each other? With Catherine Malabou, we agree that the emergence of AI in all areas of life and society demands a reinvention of trust (Shred translating Malabou, *Morphing Intelligence*, 163). Rather than build an approach to AI on a set of principles decided upon by a select few, we believe that trust suggests a kind of relationship 

As a theological school, we have spent the past 125 years investing in the pursuit of human flourishing and building communities of trust. This history positions us well to participate in the emerging collective intelligence (Malabou) that can facilitate trust-based practices in our AI ecosystem. 

Integrate.ai has done some excellent work with their agile ethics framework to introduce trust-based practices into each phase of the machine learning life cycle

What do we mean by trust

*Transparent* - Are your models explainable and your data/development practices communicated to all stakeholders?
*Responsible* - Does your use and development of AI work to increase social good? Are you aware of the impact, both actual and possible, of your development on different sectors of society?
*User-centered* - Do you involve the needs and input of users in all appropriate stages of your AI workflows? Is there a feedback mechanism for users to shape the design and implementation of AI?
*Sustainable* - Are your AI practices agile enough to respond to new technologies, new social demands, and new legislation (GDPR)?
*Tangible* - Are your practices ...

With whom does trust matter? 

Customers
Employees/Partners
Investors
